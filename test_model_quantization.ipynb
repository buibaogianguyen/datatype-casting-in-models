{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "9aca5850",
   "metadata": {},
   "outputs": [],
   "source": [
    "from test_model import TestModel\n",
    "import torch\n",
    "\n",
    "torch.manual_seed(42)\n",
    "torch.cuda.manual_seed_all(42)\n",
    "\n",
    "model = TestModel()\n",
    "x = torch.randn(16, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "44fb17ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "out = model(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "060eda5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_param_dtype(model):\n",
    "    for name, param in model.named_parameters():\n",
    "        print(f\"{name} is loaded in {param.dtype}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "9d3f3458",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([16, 8])\n",
      "\n",
      "linear1.weight is loaded in torch.float32\n",
      "linear1.bias is loaded in torch.float32\n",
      "bn1.weight is loaded in torch.float32\n",
      "bn1.bias is loaded in torch.float32\n",
      "linear2.weight is loaded in torch.float32\n",
      "linear2.bias is loaded in torch.float32\n",
      "bn2.weight is loaded in torch.float32\n",
      "bn2.bias is loaded in torch.float32\n",
      "tensor([[5.6570e-01, 2.6057e-01, 6.0959e-02, 0.0000e+00, 0.0000e+00, 6.4186e-01,\n",
      "         1.0861e+00, 7.2191e-01],\n",
      "        [0.0000e+00, 0.0000e+00, 3.4649e-01, 1.0093e+00, 6.2260e-01, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 3.4649e-01, 1.0093e+00, 6.2260e-01, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00],\n",
      "        [9.5711e-01, 1.4652e+00, 0.0000e+00, 0.0000e+00, 8.1230e-01, 9.1862e-01,\n",
      "         0.0000e+00, 0.0000e+00],\n",
      "        [1.9353e+00, 1.6048e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 2.0986e+00,\n",
      "         2.4531e+00, 1.3174e+00],\n",
      "        [6.1562e-01, 0.0000e+00, 9.0805e-01, 0.0000e+00, 0.0000e+00, 6.0938e-01,\n",
      "         1.4962e+00, 1.8144e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 8.6516e-01, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         2.1918e-01, 9.4862e-01],\n",
      "        [0.0000e+00, 0.0000e+00, 7.5170e-01, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 5.5284e-01],\n",
      "        [0.0000e+00, 0.0000e+00, 3.2644e-01, 9.9761e-01, 6.2450e-01, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00],\n",
      "        [4.7828e-01, 0.0000e+00, 8.0329e-01, 0.0000e+00, 0.0000e+00, 4.8366e-01,\n",
      "         1.2734e+00, 1.5000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 4.4752e-02, 8.3378e-01, 6.5123e-01, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 3.4649e-01, 1.0093e+00, 6.2260e-01, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 3.4649e-01, 1.0093e+00, 6.2260e-01, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 4.0321e-01, 4.4512e-01, 1.0282e+00, 0.0000e+00,\n",
      "         0.0000e+00, 3.3842e-01],\n",
      "        [2.2022e+00, 2.7564e+00, 0.0000e+00, 0.0000e+00, 9.3582e-01, 2.0962e+00,\n",
      "         2.7560e-03, 3.9908e-02],\n",
      "        [0.0000e+00, 0.0000e+00, 5.2909e-02, 7.0718e-01, 3.8479e-01, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00]], grad_fn=<ReluBackward0>)\n"
     ]
    }
   ],
   "source": [
    "print(f'{out.shape}\\n')\n",
    "\n",
    "print_param_dtype(model)\n",
    "print(out)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0994d45",
   "metadata": {},
   "source": [
    "### Cast test model into float16 (Half).\n",
    "- Outputs of the model are random, and change every time, even with a set seed. On such small values, the low-precision attribute of float16 bakes in rounding errors through multiple layers; in this case, batch norm, ReLU (removes negative values), linear. This generates different model outputs every run, in contrast to float32. float16 is also not supposed on some CPU kernels -> not an ideal data type in many cases."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "d8b98a4f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "linear1.weight is loaded in torch.float16\n",
      "linear1.bias is loaded in torch.float16\n",
      "bn1.weight is loaded in torch.float16\n",
      "bn1.bias is loaded in torch.float16\n",
      "linear2.weight is loaded in torch.float16\n",
      "linear2.bias is loaded in torch.float16\n",
      "bn2.weight is loaded in torch.float16\n",
      "bn2.bias is loaded in torch.float16\n",
      "tensor([[0.6191, 1.0479, 0.0000, 0.0000, 0.0000, 1.0869, 0.2419, 0.0000],\n",
      "        [0.0464, 0.0798, 1.3184, 0.5444, 1.0117, 0.0000, 0.0000, 1.1562],\n",
      "        [0.0000, 0.0000, 1.6455, 0.7954, 1.2188, 0.0000, 0.0000, 1.4307],\n",
      "        [0.0000, 0.0000, 0.0000, 1.4004, 0.0000, 0.0000, 1.4854, 0.3936],\n",
      "        [0.1791, 1.6289, 0.0000, 0.0000, 0.0000, 1.1074, 1.3320, 0.0000],\n",
      "        [0.6855, 0.7944, 0.0000, 0.0000, 0.0480, 1.0254, 0.0101, 0.0000],\n",
      "        [0.8228, 0.2722, 0.0000, 0.0000, 0.2527, 0.8965, 0.0000, 0.0000],\n",
      "        [0.8228, 0.2754, 0.0000, 0.0000, 0.2512, 0.8911, 0.0000, 0.0000],\n",
      "        [0.0000, 0.0000, 0.8057, 0.3936, 0.6445, 0.0000, 0.0000, 0.4932],\n",
      "        [0.6924, 0.7671, 0.0000, 0.0000, 0.0588, 1.0186, 0.0000, 0.0000],\n",
      "        [0.3391, 0.0000, 0.0000, 0.0000, 0.0545, 0.5073, 0.0000, 0.0000],\n",
      "        [0.1407, 0.0000, 0.5967, 0.0000, 0.7773, 0.0000, 0.0000, 0.1981],\n",
      "        [0.0000, 0.0000, 1.6963, 1.1611, 1.1689, 0.0000, 0.0000, 1.1992],\n",
      "        [0.8901, 1.0811, 0.7231, 0.4004, 0.0000, 0.0000, 0.0000, 1.5762],\n",
      "        [0.0000, 0.0000, 0.0000, 2.2520, 0.0000, 0.0000, 2.7676, 0.5566],\n",
      "        [0.6895, 0.3889, 0.0000, 0.0000, 0.0000, 0.8813, 0.0000, 0.0000]],\n",
      "       dtype=torch.float16, grad_fn=<ReluBackward0>)\n"
     ]
    }
   ],
   "source": [
    "model_fp16 = TestModel().to(torch.float16) # or TestModel().half()\n",
    "print_param_dtype(model_fp16)\n",
    "out_fp16 = model_fp16(x.to(torch.float16))\n",
    "print(out_fp16)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8368f074",
   "metadata": {},
   "source": [
    "### Cast test model into bfloat16.\n",
    "- bfloat16 is stable, unlike float16, and achieves the same outputs after each run with a set seed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "9042c13e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "linear1.weight is loaded in torch.bfloat16\n",
      "linear1.bias is loaded in torch.bfloat16\n",
      "bn1.weight is loaded in torch.bfloat16\n",
      "bn1.bias is loaded in torch.bfloat16\n",
      "linear2.weight is loaded in torch.bfloat16\n",
      "linear2.bias is loaded in torch.bfloat16\n",
      "bn2.weight is loaded in torch.bfloat16\n",
      "bn2.bias is loaded in torch.bfloat16\n",
      "tensor([[0.5703, 0.2412, 0.0532, 0.0000, 0.0000, 0.6211, 1.0859, 0.7109],\n",
      "        [0.0000, 0.0000, 0.3457, 1.0000, 0.6211, 0.0000, 0.0000, 0.0000],\n",
      "        [0.0000, 0.0000, 0.3457, 1.0000, 0.6211, 0.0000, 0.0000, 0.0000],\n",
      "        [0.9531, 1.4609, 0.0000, 0.0000, 0.8125, 0.9141, 0.0000, 0.0000],\n",
      "        [1.9375, 1.6172, 0.0000, 0.0000, 0.0000, 2.0938, 2.4531, 1.3125],\n",
      "        [0.6328, 0.0000, 0.9062, 0.0000, 0.0000, 0.6055, 1.5078, 1.8203],\n",
      "        [0.0000, 0.0000, 0.8516, 0.0000, 0.0000, 0.0000, 0.2178, 0.9492],\n",
      "        [0.0000, 0.0000, 0.7578, 0.0000, 0.0000, 0.0000, 0.0000, 0.5469],\n",
      "        [0.0000, 0.0000, 0.3320, 0.9961, 0.6211, 0.0000, 0.0000, 0.0000],\n",
      "        [0.5078, 0.0000, 0.7969, 0.0000, 0.0000, 0.4883, 1.2891, 1.5078],\n",
      "        [0.0000, 0.0000, 0.0466, 0.8281, 0.6523, 0.0000, 0.0000, 0.0000],\n",
      "        [0.0000, 0.0000, 0.3457, 1.0000, 0.6211, 0.0000, 0.0000, 0.0000],\n",
      "        [0.0000, 0.0000, 0.3457, 1.0000, 0.6211, 0.0000, 0.0000, 0.0000],\n",
      "        [0.0000, 0.0000, 0.3867, 0.4434, 1.0312, 0.0000, 0.0000, 0.3262],\n",
      "        [2.2188, 2.7656, 0.0000, 0.0000, 0.9336, 2.0938, 0.0000, 0.0378],\n",
      "        [0.0000, 0.0000, 0.0664, 0.7070, 0.3750, 0.0000, 0.0000, 0.0000]],\n",
      "       dtype=torch.bfloat16, grad_fn=<ReluBackward0>)\n"
     ]
    }
   ],
   "source": [
    "from copy import deepcopy\n",
    "model_bf16 = deepcopy(model)\n",
    "model_bf16 = model_bf16.to(torch.bfloat16)\n",
    "print_param_dtype(model_bf16)\n",
    "out_bf16 = model_bf16(x.to(torch.bfloat16))\n",
    "print(out_bf16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95306ef1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
