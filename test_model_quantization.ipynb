{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "9aca5850",
   "metadata": {},
   "outputs": [],
   "source": [
    "from test_model import TestModel\n",
    "import torch\n",
    "\n",
    "torch.manual_seed(42)\n",
    "torch.cuda.manual_seed_all(42)\n",
    "\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "\n",
    "model = TestModel().to(device)\n",
    "x = torch.randn(16, 2).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "44fb17ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "out_fp32 = model(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "060eda5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_param_dtype(model):\n",
    "    for name, param in model.named_parameters():\n",
    "        print(f\"{name} is loaded in {param.dtype}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "9d3f3458",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([16, 8])\n",
      "\n",
      "linear1.weight is loaded in torch.float32\n",
      "linear1.bias is loaded in torch.float32\n",
      "bn1.weight is loaded in torch.float32\n",
      "bn1.bias is loaded in torch.float32\n",
      "linear2.weight is loaded in torch.float32\n",
      "linear2.bias is loaded in torch.float32\n",
      "bn2.weight is loaded in torch.float32\n",
      "bn2.bias is loaded in torch.float32\n",
      "tensor([[5.6570e-01, 2.6057e-01, 6.0959e-02, 0.0000e+00, 0.0000e+00, 6.4186e-01,\n",
      "         1.0861e+00, 7.2191e-01],\n",
      "        [0.0000e+00, 0.0000e+00, 3.4649e-01, 1.0093e+00, 6.2260e-01, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 3.4649e-01, 1.0093e+00, 6.2260e-01, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00],\n",
      "        [9.5711e-01, 1.4652e+00, 0.0000e+00, 0.0000e+00, 8.1230e-01, 9.1862e-01,\n",
      "         0.0000e+00, 0.0000e+00],\n",
      "        [1.9353e+00, 1.6048e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 2.0986e+00,\n",
      "         2.4531e+00, 1.3174e+00],\n",
      "        [6.1562e-01, 0.0000e+00, 9.0805e-01, 0.0000e+00, 0.0000e+00, 6.0938e-01,\n",
      "         1.4962e+00, 1.8144e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 8.6517e-01, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         2.1918e-01, 9.4861e-01],\n",
      "        [0.0000e+00, 0.0000e+00, 7.5170e-01, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 5.5284e-01],\n",
      "        [0.0000e+00, 0.0000e+00, 3.2644e-01, 9.9761e-01, 6.2450e-01, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00],\n",
      "        [4.7828e-01, 0.0000e+00, 8.0329e-01, 0.0000e+00, 0.0000e+00, 4.8366e-01,\n",
      "         1.2734e+00, 1.5000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 4.4752e-02, 8.3378e-01, 6.5123e-01, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 3.4649e-01, 1.0093e+00, 6.2260e-01, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 3.4649e-01, 1.0093e+00, 6.2260e-01, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 4.0321e-01, 4.4512e-01, 1.0282e+00, 0.0000e+00,\n",
      "         0.0000e+00, 3.3842e-01],\n",
      "        [2.2022e+00, 2.7564e+00, 0.0000e+00, 0.0000e+00, 9.3582e-01, 2.0962e+00,\n",
      "         2.7561e-03, 3.9908e-02],\n",
      "        [0.0000e+00, 0.0000e+00, 5.2909e-02, 7.0718e-01, 3.8479e-01, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00]], device='cuda:0', grad_fn=<ReluBackward0>)\n"
     ]
    }
   ],
   "source": [
    "print(f'{out_fp32.shape}\\n')\n",
    "\n",
    "print_param_dtype(model)\n",
    "print(out_fp32)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0994d45",
   "metadata": {},
   "source": [
    "### Cast test model into float16 (Half).\n",
    "- Outputs of the model are random, and change every time, even with a set seed. On such small values, the low-precision attribute of float16 bakes in rounding errors through multiple layers; in this case, batch norm, ReLU (removes negative values), linear. This generates different model outputs every run, in contrast to float32. float16 is also not supposed on some CPU kernels -> not an ideal data type in many cases."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "3197a1f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_fp16 = TestModel().to(dtype = torch.float16, device = device) # or TestModel().half()\n",
    "x = x.to(torch.float16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "d8b98a4f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "linear1.weight is loaded in torch.float16\n",
      "linear1.bias is loaded in torch.float16\n",
      "bn1.weight is loaded in torch.float16\n",
      "bn1.bias is loaded in torch.float16\n",
      "linear2.weight is loaded in torch.float16\n",
      "linear2.bias is loaded in torch.float16\n",
      "bn2.weight is loaded in torch.float16\n",
      "bn2.bias is loaded in torch.float16\n",
      "tensor([[0.0000, 0.1044, 0.0000, 0.0000, 0.9800, 0.0000, 0.7773, 0.0000],\n",
      "        [0.7139, 0.0000, 0.4041, 0.0000, 0.0000, 0.0000, 0.0000, 0.7212],\n",
      "        [0.7827, 0.0000, 0.7378, 0.0000, 0.0000, 0.0000, 0.0000, 1.1035],\n",
      "        [0.0000, 0.7319, 1.1123, 1.7871, 0.1461, 1.7012, 0.0000, 0.9907],\n",
      "        [0.0000, 0.0000, 0.0000, 0.1715, 1.3926, 0.2062, 0.4624, 0.0000],\n",
      "        [0.6343, 0.0000, 0.0000, 0.0000, 0.4487, 0.0000, 1.3262, 0.0000],\n",
      "        [0.5684, 0.0000, 0.0000, 0.0000, 0.5239, 0.0000, 1.2363, 0.0000],\n",
      "        [0.4905, 0.0000, 0.0000, 0.0000, 0.6133, 0.0000, 1.1309, 0.0000],\n",
      "        [0.0703, 1.0273, 0.0000, 0.3337, 0.0000, 0.4602, 0.0000, 0.2517],\n",
      "        [0.5620, 0.0000, 0.0000, 0.0000, 0.5312, 0.0000, 1.2275, 0.0000],\n",
      "        [0.0000, 1.1113, 0.0000, 0.1066, 0.8315, 0.4434, 0.1965, 0.0000],\n",
      "        [0.2188, 0.9893, 0.0000, 0.0443, 0.0000, 0.2361, 0.0000, 0.0000],\n",
      "        [0.3367, 0.9355, 0.8735, 0.5889, 0.0000, 0.4924, 0.0000, 1.3184],\n",
      "        [1.4463, 0.0000, 1.4355, 0.0000, 0.0000, 0.0000, 0.2500, 1.0049],\n",
      "        [0.0000, 0.1748, 2.3223, 2.7363, 0.0000, 2.3379, 0.0000, 1.9580],\n",
      "        [0.0000, 0.9790, 0.0000, 0.0000, 1.1816, 0.2277, 0.5024, 0.0000]],\n",
      "       device='cuda:0', dtype=torch.float16, grad_fn=<ReluBackward0>)\n"
     ]
    }
   ],
   "source": [
    "print_param_dtype(model_fp16)\n",
    "out_fp16 = model_fp16(x)\n",
    "print(out_fp16)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8368f074",
   "metadata": {},
   "source": [
    "### Cast test model into bfloat16.\n",
    "- bfloat16 is stable, unlike float16, and achieves the same outputs after each run with a set seed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "9042c13e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "linear1.weight is loaded in torch.bfloat16\n",
      "linear1.bias is loaded in torch.bfloat16\n",
      "bn1.weight is loaded in torch.bfloat16\n",
      "bn1.bias is loaded in torch.bfloat16\n",
      "linear2.weight is loaded in torch.bfloat16\n",
      "linear2.bias is loaded in torch.bfloat16\n",
      "bn2.weight is loaded in torch.bfloat16\n",
      "bn2.bias is loaded in torch.bfloat16\n",
      "tensor([[0.5703, 0.2402, 0.0532, 0.0000, 0.0000, 0.6211, 1.0781, 0.7109],\n",
      "        [0.0000, 0.0000, 0.3457, 1.0000, 0.6211, 0.0000, 0.0000, 0.0000],\n",
      "        [0.0000, 0.0000, 0.3457, 1.0000, 0.6211, 0.0000, 0.0000, 0.0000],\n",
      "        [0.9531, 1.4609, 0.0000, 0.0000, 0.8086, 0.9141, 0.0000, 0.0000],\n",
      "        [1.9375, 1.6094, 0.0000, 0.0000, 0.0000, 2.0938, 2.4375, 1.3203],\n",
      "        [0.6328, 0.0000, 0.9062, 0.0000, 0.0000, 0.6055, 1.5000, 1.8203],\n",
      "        [0.0000, 0.0000, 0.8516, 0.0000, 0.0000, 0.0000, 0.2178, 0.9492],\n",
      "        [0.0000, 0.0000, 0.7578, 0.0000, 0.0000, 0.0000, 0.0000, 0.5469],\n",
      "        [0.0000, 0.0000, 0.3320, 0.9961, 0.6211, 0.0000, 0.0000, 0.0000],\n",
      "        [0.5078, 0.0000, 0.7969, 0.0000, 0.0000, 0.4883, 1.2812, 1.5156],\n",
      "        [0.0000, 0.0000, 0.0466, 0.8281, 0.6523, 0.0000, 0.0000, 0.0000],\n",
      "        [0.0000, 0.0000, 0.3457, 1.0000, 0.6211, 0.0000, 0.0000, 0.0000],\n",
      "        [0.0000, 0.0000, 0.3457, 1.0000, 0.6211, 0.0000, 0.0000, 0.0000],\n",
      "        [0.0000, 0.0000, 0.3867, 0.4434, 1.0312, 0.0000, 0.0000, 0.3301],\n",
      "        [2.2188, 2.7656, 0.0000, 0.0000, 0.9336, 2.0938, 0.0000, 0.0415],\n",
      "        [0.0000, 0.0000, 0.0664, 0.7070, 0.3750, 0.0000, 0.0000, 0.0000]],\n",
      "       dtype=torch.bfloat16, grad_fn=<ReluBackward0>)\n"
     ]
    }
   ],
   "source": [
    "from copy import deepcopy\n",
    "model_bf16 = deepcopy(model)\n",
    "model_bf16 = model_bf16.to(torch.bfloat16)\n",
    "print_param_dtype(model_bf16)\n",
    "out_bf16 = model_bf16(x.to(torch.bfloat16))\n",
    "print(out_bf16)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53ac26eb",
   "metadata": {},
   "source": [
    "### Compute output differences between fp32 and bf16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "95306ef1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean diff: 0.00309927249327302 | Max diff: 0.029530048370361328\n"
     ]
    }
   ],
   "source": [
    "mean_diff = torch.abs(out_bf16 - out_fp32).mean().item()\n",
    "max_diff = torch.abs(out_bf16 - out_fp32).max().item()\n",
    "\n",
    "print(f\"Mean diff: {mean_diff} | Max diff: {max_diff}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17bfd383",
   "metadata": {},
   "source": [
    "### Output logits hold similar values, small differences between the full-precision model and the bf16 model.\n",
    "- Does not lead to a huge performance degradation, even on large models."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
