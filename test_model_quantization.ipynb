{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9aca5850",
   "metadata": {},
   "outputs": [],
   "source": [
    "from test_model import TestModel\n",
    "import torch\n",
    "\n",
    "torch.manual_seed(42)\n",
    "torch.cuda.manual_seed_all(42)\n",
    "\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "\n",
    "model = TestModel().to(device)\n",
    "model.eval()\n",
    "x = torch.randn(16, 2).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "44fb17ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "out_fp32 = model(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "060eda5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_param_dtype(model):\n",
    "    for name, param in model.named_parameters():\n",
    "        print(f\"{name} is loaded in {param.dtype}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9d3f3458",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([16, 8])\n",
      "\n",
      "linear1.weight is loaded in torch.float32\n",
      "linear1.bias is loaded in torch.float32\n",
      "bn1.weight is loaded in torch.float32\n",
      "bn1.bias is loaded in torch.float32\n",
      "linear2.weight is loaded in torch.float32\n",
      "linear2.bias is loaded in torch.float32\n",
      "bn2.weight is loaded in torch.float32\n",
      "bn2.bias is loaded in torch.float32\n",
      "tensor([[0.8541, 0.1149, 0.1141, 0.0000, 0.1887, 0.2379, 0.0000, 0.4394],\n",
      "        [0.4347, 0.0000, 0.1950, 0.0000, 0.4956, 0.0000, 0.0000, 0.0000],\n",
      "        [0.4341, 0.0000, 0.1766, 0.0000, 0.5147, 0.0000, 0.0000, 0.0000],\n",
      "        [1.0019, 0.3521, 0.0000, 0.0000, 0.4951, 0.2923, 0.0000, 0.1099],\n",
      "        [1.0963, 0.3803, 0.0000, 0.0000, 0.0000, 0.5342, 0.0000, 0.5385],\n",
      "        [0.7830, 0.0401, 0.2393, 0.0000, 0.0000, 0.2328, 0.0000, 0.5426],\n",
      "        [0.6002, 0.0000, 0.2864, 0.0000, 0.2534, 0.0000, 0.0000, 0.4049],\n",
      "        [0.5767, 0.0000, 0.2725, 0.0000, 0.3464, 0.0000, 0.0000, 0.3579],\n",
      "        [0.6742, 0.0000, 0.0204, 0.0000, 0.5273, 0.0000, 0.0000, 0.0123],\n",
      "        [0.7778, 0.0336, 0.2204, 0.0000, 0.0496, 0.2069, 0.0000, 0.5090],\n",
      "        [0.7365, 0.0000, 0.0279, 0.0000, 0.5000, 0.0000, 0.0000, 0.1304],\n",
      "        [0.6282, 0.0000, 0.0661, 0.0000, 0.5175, 0.0000, 0.0000, 0.0361],\n",
      "        [0.5996, 0.0000, 0.0721, 0.0000, 0.4762, 0.0000, 0.0000, 0.0000],\n",
      "        [0.4528, 0.0000, 0.3086, 0.0000, 0.3910, 0.0000, 0.0000, 0.2445],\n",
      "        [1.2147, 0.6358, 0.0000, 0.0000, 0.4689, 0.5673, 0.0000, 0.1717],\n",
      "        [0.7431, 0.0000, 0.0706, 0.0000, 0.4569, 0.0176, 0.0000, 0.2241]],\n",
      "       device='cuda:0', grad_fn=<ReluBackward0>)\n"
     ]
    }
   ],
   "source": [
    "print(f'{out_fp32.shape}\\n')\n",
    "\n",
    "print_param_dtype(model)\n",
    "print(out_fp32)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0994d45",
   "metadata": {},
   "source": [
    "### Cast test model into float16 (Half).\n",
    "- Casting the entire model to fp16 interacts badly with batch norm layers. \n",
    "- float16 is also not supposed on some CPU kernels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3197a1f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_fp16 = TestModel().to(dtype = torch.float16, device = device) # or TestModel().half()\n",
    "model_fp16.eval()\n",
    "x = x.to(torch.float16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "d8b98a4f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "linear1.weight is loaded in torch.float16\n",
      "linear1.bias is loaded in torch.float16\n",
      "bn1.weight is loaded in torch.float16\n",
      "bn1.bias is loaded in torch.float16\n",
      "linear2.weight is loaded in torch.float16\n",
      "linear2.bias is loaded in torch.float16\n",
      "bn2.weight is loaded in torch.float16\n",
      "bn2.bias is loaded in torch.float16\n",
      "tensor([[0.1161, 0.2583, 0.0906, 0.0000, 0.2610, 0.2627, 0.1870, 0.0000],\n",
      "        [0.4341, 0.2399, 0.2913, 0.0344, 0.5327, 0.1770, 0.1666, 0.0000],\n",
      "        [0.4849, 0.2382, 0.3276, 0.0719, 0.5742, 0.1587, 0.1602, 0.0000],\n",
      "        [0.0000, 0.0000, 0.0000, 0.0000, 0.6655, 0.0000, 0.0000, 0.0000],\n",
      "        [0.1161, 0.2583, 0.0906, 0.0000, 0.2610, 0.2627, 0.1870, 0.0000],\n",
      "        [0.1161, 0.2583, 0.0906, 0.0000, 0.2610, 0.2627, 0.1870, 0.0000],\n",
      "        [0.1552, 0.2537, 0.1135, 0.0000, 0.2791, 0.2722, 0.2109, 0.0000],\n",
      "        [0.1766, 0.2510, 0.1261, 0.0000, 0.2888, 0.2776, 0.2241, 0.0000],\n",
      "        [0.0000, 0.1134, 0.0000, 0.0000, 0.4780, 0.0280, 0.0000, 0.0000],\n",
      "        [0.1161, 0.2583, 0.0906, 0.0000, 0.2610, 0.2627, 0.1870, 0.0000],\n",
      "        [0.0000, 0.1353, 0.0170, 0.0000, 0.4148, 0.1423, 0.0012, 0.0000],\n",
      "        [0.0000, 0.1606, 0.0183, 0.0000, 0.4238, 0.0858, 0.0000, 0.0000],\n",
      "        [0.0000, 0.0879, 0.0000, 0.0000, 0.5459, 0.0000, 0.0000, 0.0000],\n",
      "        [0.9155, 0.2529, 0.5767, 0.6074, 0.5737, 0.4033, 0.6074, 0.0000],\n",
      "        [0.0000, 0.0000, 0.0000, 0.0000, 0.7979, 0.0000, 0.0000, 0.0000],\n",
      "        [0.0408, 0.1653, 0.0358, 0.0000, 0.3623, 0.2208, 0.1094, 0.0000]],\n",
      "       device='cuda:0', dtype=torch.float16, grad_fn=<ReluBackward0>)\n"
     ]
    }
   ],
   "source": [
    "print_param_dtype(model_fp16)\n",
    "out_fp16 = model_fp16(x)\n",
    "print(out_fp16)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2549cd8a",
   "metadata": {},
   "source": [
    "#### Instead, cast using mixed precision:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "e7e0a6ae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.8540, 0.1149, 0.1140, 0.0000, 0.1888, 0.2378, 0.0000, 0.4390],\n",
      "        [0.4348, 0.0000, 0.1949, 0.0000, 0.4956, 0.0000, 0.0000, 0.0000],\n",
      "        [0.4341, 0.0000, 0.1765, 0.0000, 0.5146, 0.0000, 0.0000, 0.0000],\n",
      "        [1.0020, 0.3521, 0.0000, 0.0000, 0.4951, 0.2925, 0.0000, 0.1100],\n",
      "        [1.0967, 0.3809, 0.0000, 0.0000, 0.0000, 0.5347, 0.0000, 0.5386],\n",
      "        [0.7832, 0.0404, 0.2394, 0.0000, 0.0000, 0.2334, 0.0000, 0.5425],\n",
      "        [0.6006, 0.0000, 0.2861, 0.0000, 0.2537, 0.0000, 0.0000, 0.4048],\n",
      "        [0.5767, 0.0000, 0.2725, 0.0000, 0.3467, 0.0000, 0.0000, 0.3579],\n",
      "        [0.6743, 0.0000, 0.0203, 0.0000, 0.5273, 0.0000, 0.0000, 0.0123],\n",
      "        [0.7778, 0.0338, 0.2205, 0.0000, 0.0494, 0.2075, 0.0000, 0.5088],\n",
      "        [0.7363, 0.0000, 0.0278, 0.0000, 0.5000, 0.0000, 0.0000, 0.1305],\n",
      "        [0.6284, 0.0000, 0.0658, 0.0000, 0.5176, 0.0000, 0.0000, 0.0363],\n",
      "        [0.5996, 0.0000, 0.0719, 0.0000, 0.4763, 0.0000, 0.0000, 0.0000],\n",
      "        [0.4529, 0.0000, 0.3083, 0.0000, 0.3911, 0.0000, 0.0000, 0.2445],\n",
      "        [1.2148, 0.6357, 0.0000, 0.0000, 0.4690, 0.5669, 0.0000, 0.1718],\n",
      "        [0.7432, 0.0000, 0.0703, 0.0000, 0.4570, 0.0178, 0.0000, 0.2240]],\n",
      "       device='cuda:0', dtype=torch.float16, grad_fn=<ReluBackward0>)\n"
     ]
    }
   ],
   "source": [
    "with torch.amp.autocast(device):\n",
    "    out_fp16_autocast = model(x)\n",
    "\n",
    "print(out_fp16_autocast)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c4e680d",
   "metadata": {},
   "source": [
    "- Very close to fp32, but might not be ideal for deeper models"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8368f074",
   "metadata": {},
   "source": [
    "### Cast test model into bfloat16.\n",
    "- bfloat16 is a more stable, and better alternative to fp16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "9042c13e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "linear1.weight is loaded in torch.bfloat16\n",
      "linear1.bias is loaded in torch.bfloat16\n",
      "bn1.weight is loaded in torch.bfloat16\n",
      "bn1.bias is loaded in torch.bfloat16\n",
      "linear2.weight is loaded in torch.bfloat16\n",
      "linear2.bias is loaded in torch.bfloat16\n",
      "bn2.weight is loaded in torch.bfloat16\n",
      "bn2.bias is loaded in torch.bfloat16\n",
      "tensor([[0.5703, 0.2402, 0.0532, 0.0000, 0.0000, 0.6211, 1.0781, 0.7109],\n",
      "        [0.0000, 0.0000, 0.3457, 1.0000, 0.6211, 0.0000, 0.0000, 0.0000],\n",
      "        [0.0000, 0.0000, 0.3457, 1.0000, 0.6211, 0.0000, 0.0000, 0.0000],\n",
      "        [0.9531, 1.4609, 0.0000, 0.0000, 0.8086, 0.9141, 0.0000, 0.0000],\n",
      "        [1.9375, 1.6094, 0.0000, 0.0000, 0.0000, 2.0938, 2.4375, 1.3203],\n",
      "        [0.6328, 0.0000, 0.9062, 0.0000, 0.0000, 0.6055, 1.5000, 1.8203],\n",
      "        [0.0000, 0.0000, 0.8516, 0.0000, 0.0000, 0.0000, 0.2178, 0.9492],\n",
      "        [0.0000, 0.0000, 0.7578, 0.0000, 0.0000, 0.0000, 0.0000, 0.5469],\n",
      "        [0.0000, 0.0000, 0.3320, 0.9961, 0.6211, 0.0000, 0.0000, 0.0000],\n",
      "        [0.5078, 0.0000, 0.7969, 0.0000, 0.0000, 0.4883, 1.2812, 1.5156],\n",
      "        [0.0000, 0.0000, 0.0466, 0.8281, 0.6523, 0.0000, 0.0000, 0.0000],\n",
      "        [0.0000, 0.0000, 0.3457, 1.0000, 0.6211, 0.0000, 0.0000, 0.0000],\n",
      "        [0.0000, 0.0000, 0.3457, 1.0000, 0.6211, 0.0000, 0.0000, 0.0000],\n",
      "        [0.0000, 0.0000, 0.3867, 0.4434, 1.0312, 0.0000, 0.0000, 0.3301],\n",
      "        [2.2188, 2.7656, 0.0000, 0.0000, 0.9336, 2.0938, 0.0000, 0.0415],\n",
      "        [0.0000, 0.0000, 0.0664, 0.7070, 0.3750, 0.0000, 0.0000, 0.0000]],\n",
      "       dtype=torch.bfloat16, grad_fn=<ReluBackward0>)\n"
     ]
    }
   ],
   "source": [
    "from copy import deepcopy\n",
    "model_bf16 = deepcopy(model)\n",
    "model_bf16 = model_bf16.to(torch.bfloat16)\n",
    "print_param_dtype(model_bf16)\n",
    "out_bf16 = model_bf16(x.to(torch.bfloat16))\n",
    "print(out_bf16)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53ac26eb",
   "metadata": {},
   "source": [
    "### Compute output differences between fp32 and bf16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "95306ef1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean diff: 0.00309927249327302 | Max diff: 0.029530048370361328\n"
     ]
    }
   ],
   "source": [
    "mean_diff = torch.abs(out_bf16 - out_fp32).mean().item()\n",
    "max_diff = torch.abs(out_bf16 - out_fp32).max().item()\n",
    "\n",
    "print(f\"Mean diff: {mean_diff} | Max diff: {max_diff}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17bfd383",
   "metadata": {},
   "source": [
    "### Output logits hold similar values, small differences between the full-precision model and the bf16 model.\n",
    "- Does not lead to a huge performance degradation, even on large models."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
